---
title: "Raport 3"
subtitle: "Eksploracja danych"
author:   |
          |    Mikołaj Langner, Marcin Kostrzewa
          |    nr albumów: 255716, 255749
date: "2021-04-19"
output: 
  pdf_document:
    toc: true
    fig_caption: yes
    fig_width: 5 
    fig_height: 4 
    number_sections: true
    includes:
      in_header: "preambula.tex" 
fontsize: 12pt 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=6, fig.height=4, fig.pos='H')
library(DataExplorer)
library(datasets)
library(dplyr)
library(tidyr)
library(kableExtra)
library(xtable)
library(ggplot2)
library(reshape2)
library(wesanderson)
library(e1071)
library(caret)
library(mlbench)
library(class)
library(rpart)
library(rpart.plot)
library(ipred)
library(rattle)
library(naivebayes)
```


# Wstęp

Raport zawiera rozwiązania listy $3$.

W zadaniu pierwszym budujemy klasyfikator na bazie metody regresji liniowej i oceniamy jego skuteczność i dokładność.

W zadaniu drugim \ldots.Porównamy ze sobą rezultaty zastosowania:

\begin{itemize}
  \item metoda k-najblizszych sasiadów (\textit{k-Nearest Neighbors}),
  \item drzewa klasyfikacyjne (\textit{classification trees}),
  \item naiwny klasyfikator bayesowski (\textit{na{\"\i}ve Bayes classifier}).
\end{itemize}

\newpage

# Zadanie 1

## Wczytanie danych i podział na zbiór uczący i testowy

<!--Tutaj jeszcze trochę napiszę o klasach irysów-->
Wczytajmy dane o irysach i podzielmy je na zbiór uczący i testowy w proporcji $1:2$.

```{r}
data(iris)
n <- dim(iris)[1]

train.set.index <- sample(1:n, 2/3*n)
train.set <- iris %>% slice(train.set.index) %>% arrange(Species)
test.set <- iris %>% slice(-train.set.index) %>% arrange(Species)
```


## Konstrukcja klasyfikatora i wyznaczenie prognoz

Stworzymy teraz macierze eksperymentu i wskaźnikową zarówno dla zbioru uczącego, jak i testowego. W tym celu wykorzystamy funckję `dummyVars` z pakietu Caret.

```{r}
dummies <- dummyVars(" ~ .", data=iris)

train.dummies <- predict(dummies, newdata = train.set)
train.X <- as.matrix(cbind(rep(1, nrow(train.dummies)), 
                           train.dummies[, 1:4]))
train.Y <- train.dummies[, 5:7]

test.dummies <- predict(dummies, newdata = test.set) 
test.X <- as.matrix(cbind(rep(1, nrow(test.dummies)), test.dummies[, 1:4]))
test.Y <- test.dummies[, 5:7]
```

Wykorzystując metodę najmniejszych kwadratów, wyznaczamy przewidywane prognozy klas dla obu zbiorów.
```{r}
Y.hat <- solve(t(train.X) %*% train.X) %*% t(train.X) %*% train.Y

train.proba <- train.X %*% Y.hat
test.proba <- test.X %*% Y.hat
```

Przedstawmy prognozy klas na wykresach.

```{r train_plot, echo=FALSE, message=FALSE, fig.height=3, fig.cap="Prognozy klas dla zbioru uczacego."}
train.plot <- melt(as.data.frame(train.proba))
train.plot$id <- as.integer(rownames(train.proba))
ggplot(train.plot, aes(x=id, y=value, color=variable)) +
  geom_point()
```

```{r test_plot, echo=FALSE, message=FALSE, fig.height=3, fig.cap="Prognozy klas dla zbioru testowego."}
train.prediction <- colnames(train.proba)[apply(train.proba, 1, which.max)]
test.plot <- melt(as.data.frame(test.proba))
test.plot$id <- as.integer(rownames(test.proba))
ggplot(test.plot, aes(x=id, y=value, color=variable)) +
  geom_point()
```

\newpage

## Ocena jakości klasyfikacji

Wyznaczmy teraz macierz pomyłek dla zbioru uczącego.

```{r training_confusion_matrix, echo=FALSE, eval=TRUE, results='asis'}
train.confusion <- table(train.set$Species, train.prediction)

tab1 <- xtable(train.confusion, digits = 3, row.names = TRUE, caption = "Macierz pomylek dla zbioru uczacego.", label = "tab:tabela1")
print(tab1, type = "latex", table.placement = "H", comment=FALSE)
```

Błąd klasyfikacji to `r 1 - sum(diag(train.confusion)) / length(train.prediction)`.

```{r testing_confusion_matrix, echo=FALSE, eval=TRUE, results='asis'}
test.prediction <- colnames(test.proba)[apply(test.proba, 1, which.max)]
test.confusion <- table(test.set$Species, test.prediction)

tab2 <- xtable(test.confusion, digits = 3, row.names = TRUE, caption = "Macierz pomylek dla zbioru testowego.", label = "tab:tabela2")
print(tab2, type = "latex", table.placement = "H", comment=FALSE)
```

Błąd klasyfikacji wynosi `r  1 - sum(diag(test.confusion)) / length(test.prediction)`.

Wnioski i napomnienie o maskowaniu


## Zastosowanie regresji liniowej do modelu o rozszerzonej ilości cech

Najpierw uzupełnijmy dane o irysach o składniki wielomianowe stopnia $2$.

```{r}
iris.quad <- (iris %>% select(-Species))^2
colnames(iris.quad) <- c("SL^2", "SW^2", "PL^2", "PW^2")
iris <- cbind(iris, combn(iris %>% select(-Species), 2, 
                          FUN = Reduce, f = `*`), 
              iris.quad)
```

Podobnie jak poprzednio podzielimy dane na zbiory: uczący i testowy, a następnie utworzymy macierze: eksperymentu i indykatorów.

```{r}
train.set.index <- sample(1:n, 2/3*n)
train.set <- iris %>% slice(train.set.index) %>% arrange(Species)
test.set <- iris %>% slice(-train.set.index) %>% arrange(Species)

dummies <- dummyVars(" ~ .", data=iris)
train.dummies <- predict(dummies, newdata = train.set)
train.X <- as.matrix(cbind(rep(1, nrow(train.dummies)), train.dummies[, -c(5:7)]))
train.Y <- train.dummies[, 5:7]
test.dummies <- predict(dummies, newdata = test.set) 
test.X <- as.matrix(cbind(rep(1, nrow(test.dummies)), test.dummies[, -c(5:7)]))
test.Y <- test.dummies[, 5:7]
```

Ponownie, wyznaczymy prognozy klas i zwizualizujemy to przypisanie na wykresach.
```{r}
Y.hat <- solve(t(train.X) %*% train.X) %*% t(train.X) %*% train.Y

train.proba <- train.X %*% Y.hat
test.proba <- test.X %*% Y.hat
```

```{r train_plot_2, echo=FALSE, message=FALSE, fig.height=2.8, fig.cap="Prognozy klas dla zbioru uczacego o rozszerzonej liczbie cech."}
train.plot <- melt(as.data.frame(train.proba))
train.plot$id <- as.integer(rownames(train.proba))
ggplot(train.plot, aes(x=id, y=value, color=variable)) +
  geom_point()
```

```{r test_plot_2, echo=FALSE, message=FALSE, fig.height=2.8, fig.cap="Prognozy klas dla zbioru uczacego o rozszerzonej liczbie cech."}
test.plot <- melt(as.data.frame(test.proba))
test.plot$id <- as.integer(rownames(test.proba))
ggplot(test.plot, aes(x=id, y=value, color=variable)) +
  geom_point()
```

Wyznaczymy także macierze pomyłek i błędy klasyfikacji.

```{r training_confusion_matrix_2, echo=FALSE, eval=TRUE, results='asis'}
train.prediction <- colnames(train.proba)[apply(train.proba, 1, which.max)]
train.confusion <- table(train.set$Species, train.prediction)

tab3 <- xtable(train.confusion, digits = 3, row.names = TRUE, caption = "Macierz pomylek dla zbioru uczacego dla przypadku o rozszerzonej liczbie cech.", label = "tab:tabela3")
print(tab3, type = "latex", table.placement = "H", comment=FALSE)
```
Błąd klasyfkacji wynosi `r 1 - sum(diag(train.confusion)) / length(train.prediction)`. 


```{r testing_confusion_matrix_2, echo=FALSE, eval=TRUE, results='asis'}
test.prediction <- colnames(test.proba)[apply(test.proba, 1, which.max)]
test.confusion <- table(test.set$Species, test.prediction)

tab4 <- xtable(test.confusion, digits = 3, row.names = TRUE, caption = "Macierz pomylek dla zbioru testowego dla przypadku o rozszerzonej liczbie cech.", label = "tab:tabela4")
print(tab4, type = "latex", table.placement = "H", comment=FALSE)
```

Błąd klasyfikacji wynosi `r 1 - sum(diag(test.confusion)) / length(test.prediction)`.

Wnioski i napomnienie o maskowaniu

\newpage

# Zadanie 2

## Wczytanie i krótka anliza danych

Wczytajmy i przygotujmy dane do dalszych analizy.

```{r loading_and_preparing_data, message=FALSE}
library(MASS)
data(wine)
n <- dim(wine)[1]
wine <- drop_na(wine)
```


Przyjrzyjmy się naszym danym na wykresach pudełkowych.

```{r Glass_boxplot, echo=FALSE, eval=TRUE, fig.cap="Wykresy pudelkowe naszych danych."}
plot_boxplot(wine, by="Type")
```

Możemy zauważyć, że zmiennymi, które dobrze odróźniają zmienne \ldots

Podzielmy nasze dane na zbiór uczący i testowy w stosunku $2:1$.

```{r learning and training test}
set.seed(42)
train.index <- sample(n, 2/3 * n)
train.data <- wine %>% slice(train.index)
test.data <- wine %>% slice(-train.index)
train.subset <- data.frame(train.data[, c(1, 3, 6, 10)])
test.subset <- data.frame(test.data[, c(1, 3, 6, 10)])
```

```{r classes etiquettes}
train.etiquettes <- train.data$Type
test.etiquettes <- test.data$Type
subset.train.etiquettes <- train.subset$Type
subset.test.etiquettes <- test.subset$Type
```

```{r tuning}
cv <- trainControl(method="cv", number=5)
```

## Metoda k-najbliższych sąsiadów 


```{r basic_knn}
model.knn.basic <- ipredknn(Type ~ ., data = train.data, k=5)

basic.knn.test.pred <- predict(model.knn.basic, test.data, type="class")
basic.knn.train.pred <- predict(model.knn.basic, train.data, type="class")
```

```{r echo=FALSE, eval=TRUE}
test.confusion <- table(basic.knn.test.pred, test.etiquettes)
train.confusion <- table(basic.knn.train.pred, train.etiquettes)

print(xtable(train.confusion), file="knn1.tex", floating=FALSE)
print(xtable(test.confusion), file="knn2.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabknn1}{\input{./knn1}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabknn2}{\input{./knn2}}}
\caption{Macierze pomylek dla metody KNN --- wszystkie cechy.}
\label{tab:tab_knn1}
\end{table}

Błędy klasyfikacji to `r 1 - sum(diag(train.confusion)) / length(subset.train.etiquettes) ` i `r 1 - sum(diag(test.confusion)) / length(subset.test.etiquettes)`.

```{r subset_knn}
knn.model.subset <- ipredknn(Type ~ ., data = train.subset, k=5)

subset.knn.test.pred <- predict(knn.model.subset, test.subset, type="class")
subset.knn.train.pred <- predict(knn.model.subset, train.subset, type="class")
```

```{r echo=FALSE, eval=TRUE}
test.confusion <- table(basic.knn.test.pred, test.etiquettes)
train.confusion <- table(basic.knn.train.pred, train.etiquettes)

print(xtable(train.confusion), file="knn3.tex", floating=FALSE)
print(xtable(test.confusion), file="knn4.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabknn3}{\input{./knn3}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabknn4}{\input{./knn4}}}
\caption{Macierze pomylek dla metody KNN --- wybrance cechy.}
\label{tab:tab_knn2}
\end{table}

Błędy klasyfikacji to `r 1 - sum(diag(train.confusion)) / length(subset.train.etiquettes) ` i `r 1 - sum(diag(test.confusion)) / length(subset.test.etiquettes)`.


```{r tuned_knn}
model <- train(Type ~ ., data = train.data, method = "knn", trControl = cv)

tuned.knn.test.pred <- predict(model, test.data)
tuned.knn.train.pred <- predict(model, train.data)
```

```{r echo=FALSE, eval=TRUE}
test.confusion <- table(tuned.knn.test.pred, test.etiquettes)
train.confusion <- table(tuned.knn.train.pred, train.etiquettes)

print(xtable(train.confusion), file="knn5.tex", floating=FALSE)
print(xtable(test.confusion), file="knn6.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabknn5}{\input{./knn5}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabknn6}{\input{./knn6}}}
\caption{Macierze pomylek dla metody KNN --- stuningowany model.}
\label{tab:tab_knn3}
\end{table}

Błędy klasyfikacji to `r 1 - sum(diag(train.confusion)) / length(subset.train.etiquettes) ` i `r 1 - sum(diag(test.confusion)) / length(subset.test.etiquettes)`.

## Drzewa klasyfikacyjne

```{r}
basic.tree.model <- rpart(Type ~ ., data = train.data)

basic.tree.test.pred <- predict(basic.tree.model, newdata = test.data, 
                                type = "class")
basic.tree.train.pred <- predict(basic.tree.model, newdata = train.data, 
                                 type = "class")
```

```{r echo=FALSE, eval=TRUE}
fancyRpartPlot(basic.tree.model, sub="")
```


```{r echo=FALSE, eval=TRUE}
test.confusion <- table(basic.tree.test.pred, test.etiquettes)
train.confusion <- table(basic.tree.train.pred, train.etiquettes)

print(xtable(train.confusion), file="t1.tex", floating=FALSE)
print(xtable(test.confusion), file="t2.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabt1}{\input{./t1}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabt2}{\input{./t2}}}
\caption{Macierze pomylek dla metody drzew klasyfikacyjnych --- wszystkie cechy.}
\label{tab:tab_t1}
\end{table}

Błędy klasyfikacji to `r 1 - sum(diag(train.confusion)) / length(subset.train.etiquettes) ` i `r 1 - sum(diag(test.confusion)) / length(subset.test.etiquettes)`.

```{r}
subset.tree.model <- rpart(Type ~ ., data = train.subset)

subset.tree.test.pred <- predict(subset.tree.model, newdata = test.subset, 
                                 type = "class")
subset.tree.train.pred <- predict(subset.tree.model, newdata = train.subset,
                                  type = "class")
```

```{r echo=FALSE, eval=TRUE}
fancyRpartPlot(subset.tree.model, sub="")
```


```{r echo=FALSE, eval=TRUE}
test.confusion <- table(subset.tree.test.pred, subset.test.etiquettes)
train.confusion <- table(subset.tree.train.pred, subset.train.etiquettes)

print(xtable(train.confusion), file="t3.tex", floating=FALSE)
print(xtable(test.confusion), file="t4.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabt3}{\input{./t3}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabt4}{\input{./t4}}}
\caption{Macierze pomylek dla metody drzew klasyfikacyjnych --- wybrane cechy.}
\label{tab:tab_t2}
\end{table}

Błędy klasyfikacji to `r 1 - sum(diag(train.confusion)) / length(subset.train.etiquettes) ` i `r 1 - sum(diag(test.confusion)) / length(subset.test.etiquettes)`.


```{r}
tuned.tree.model <- train(Type ~ ., data = train.data, method = "rpart",
                          trControl = cv)

tuned.tree.test.pred <- predict(tuned.tree.model, test.data)
tuned.tree.train.pred <- predict(tuned.tree.model, train.data)
```


```{r echo=FALSE, eval=TRUE}
fancyRpartPlot(tuned.tree.model$finalModel, sub="")
```


```{r echo=FALSE, eval=TRUE}
test.confusion <- table(tuned.tree.test.pred, test.etiquettes)
train.confusion <- table(tuned.tree.train.pred, train.etiquettes)

print(xtable(train.confusion), file="t5.tex", floating=FALSE)
print(xtable(test.confusion), file="t6.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabt5}{\input{./t5}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabt6}{\input{./t6}}}
\caption{Macierze pomylek dla metody drzew klasyfikacyjnych --- stuningowany model.}
\label{tab:tab_t3}
\end{table}

Błędy klasyfikacji to `r 1 - sum(diag(train.confusion)) / length(subset.train.etiquettes) ` i `r 1 - sum(diag(test.confusion)) / length(subset.test.etiquettes)`.

## Naiwny klasyfikator bayesowski


```{r basic_bayes}
bayes.model.basic <- naiveBayes(Type ~ ., data = train.data)

basic.bayes.train.pred <- predict(bayes.model.basic, train.data) 
basic.bayes.test.pred <- predict(bayes.model.basic, test.data)
```

```{r basic_bayes_tables, echo=FALSE, eval=TRUE}
test.confusion <- table(test.etiquettes, basic.bayes.test.pred)
train.confusion <- table(train.etiquettes, basic.bayes.train.pred)

print(xtable(train.confusion), file="b1.tex", floating=FALSE)
print(xtable(test.confusion), file="b2.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabb1}{\input{./b1}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabb2}{\input{./b2}}}
\caption{Macierze pomylek dla klasyfikatora bayesowskiego --- wszystkie cechy.}
\label{tab:tab_b1}
\end{table}

Błędy klasyfikacji to kolejno `r 1 - sum(diag(train.confusion)) / length(train.etiquettes)` i `r 1 - sum(diag(test.confusion)) / length(test.etiquettes)`.

Powtórzmy teraz powyższe dla wybranego podzbioru naszych danych.

```{r subset_bayes}
bayes.model.subset <- naiveBayes(Type ~ ., data = train.subset)

basic.bayes.train.pred <- predict(bayes.model.subset, train.subset) 
basic.bayes.test.pred <- predict(bayes.model.subset, test.subset)
```

```{r subset_bayes_tables, echo=FALSE, eval=TRUE}
test.confusion <- table(subset.test.etiquettes, basic.bayes.test.pred)
train.confusion <- table(subset.train.etiquettes, basic.bayes.train.pred)

print(xtable(train.confusion), file="b3.tex", floating=FALSE)
print(xtable(test.confusion), file="b4.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabb3}{\input{./b3}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabb4}{\input{./b4}}}
\caption{Macierze pomylek dla klasyfikatora bayesowskiego --- wybrane cechy.}
\label{tab:tab_b2}
\end{table}

Błędy klasyfikacji to kolejno `r 1 - sum(diag(train.confusion)) / length(train.etiquettes)` i `r 1 - sum(diag(test.confusion)) / length(test.etiquettes)`.

Model "stunigowany"

```{r}
model <- train(Type ~ ., data = train.data, method = "naive_bayes", 
               trControl = cv)
```

```{r echo=FALSE, eval=TRUE}
test.confusion <- table(test.data$Type, predict(model, test.data))
train.confusion <- table(train.data$Type, predict(model, train.data))

print(xtable(train.confusion), file="b5.tex", floating=FALSE)
print(xtable(test.confusion), file="b6.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:tabb5}{\input{./b5}}}\quad
\subfloat[Zbior testowy]{\label{tab:tabb6}{\input{./b6}}}
\caption{Macierze pomylek dla klasyfikatora bayesowskiego --- model stuningowany.}
\label{tab:tab_b3}
\end{table}

Błędy klasyfikacji w tym przypadku to kolejno `r 1 - sum(diag(train.confusion)) / length(train.etiquettes)` i `r 1 - sum(diag(test.confusion)) / length(test.etiquettes)`.


```{r}
# my.predict  <- function(model, newdata) 
# { predict(model, newdata=newdata) }
# 
# 
# cv <- trainControl(method="cv", number=5)
# 
# 
# my.naiveBayes <- function(formula, data) 
# { train(formula, data = data, method = "naive_bayes", trControl = cv)} 
# 
# 
# my.tree <- function(formula, data)
# { }
# 
# 
# my.knn <- function(formula, data)
# { }
# 
# 
# blad.cv <- errorest(Class~., BreastCancer, model=my.naiveBayes, predict=my.predict, 
#             estimator="cv", est.para=control.errorest(k = 5))
```

