---
title: "Raport 3"
subtitle: "Eksploracja danych"
author:   |
          |    Mikołaj Langner, Marcin Kostrzewa
          |    nr albumów: 255716, 255749
date: "2021-04-19"
output: 
  pdf_document:
    toc: true
    fig_caption: yes
    fig_width: 5 
    fig_height: 4 
    number_sections: true
    includes:
      in_header: "preambula.tex" 
fontsize: 12pt 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=6, fig.height=4, fig.pos='H')
library(DataExplorer)
library(datasets)
library(dplyr)
library(tidyr)
library(kableExtra)
library(xtable)
library(ggplot2)
library(reshape2)
library(wesanderson)
library(e1071)
library(caret)
library(mlbench)
library(class)
library(rpart)
library(rpart.plot)
library(ipred)
library(rattle)
library(naivebayes)
```


# Wstęp

Raport zawiera rozwiązania listy $3$.

W zadaniu pierwszym budujemy klasyfikator na bazie metody regresji liniowej i oceniamy jego skuteczność i dokładność.

W zadaniu drugim \ldots.Porównamy ze sobą rezultaty zastosowania:

\begin{itemize}
  \item metoda k-najblizszych sasiadów (\textit{k-Nearest Neighbors}),
  \item drzewa klasyfikacyjne (\textit{classification trees}),
  \item naiwny klasyfikator bayesowski (\textit{na{\"\i}ve Bayes classifier}).
\end{itemize}

\newpage

# Zadanie 1

## Wczytanie danych i podział na zbiór uczący i testowy

<!--Tutaj jeszcze trochę napiszę o klasach irysów-->
Wczytajmy dane o irysach i podzielmy je na zbiór uczący i testowy w proporcji $1:2$.

```{r}
data(iris)
n <- dim(iris)[1]

train.set.index <- sample(1:n, 2/3*n)
train.set <- iris %>% slice(train.set.index) %>% arrange(Species)
test.set <- iris %>% slice(-train.set.index) %>% arrange(Species)
```


## Konstrukcja klasyfikatora i wyznaczenie prognoz

Stworzymy teraz macierze eksperymentu i wskaźnikową zarówno dla zbioru uczącego, jak i testowego. W tym celu wykorzystamy funckję `dummyVars` z pakietu Caret.

```{r}
dummies <- dummyVars(" ~ .", data=iris)

train.dummies <- predict(dummies, newdata = train.set)
train.X <- as.matrix(cbind(rep(1, nrow(train.dummies)), 
                           train.dummies[, 1:4]))
train.Y <- train.dummies[, 5:7]

test.dummies <- predict(dummies, newdata = test.set) 
test.X <- as.matrix(cbind(rep(1, nrow(test.dummies)), test.dummies[, 1:4]))
test.Y <- test.dummies[, 5:7]
```

Wykorzystując metodę najmniejszych kwadratów, wyznaczamy przewidywane prognozy klas dla obu zbiorów.
```{r}
Y.hat <- solve(t(train.X) %*% train.X) %*% t(train.X) %*% train.Y

train.proba <- train.X %*% Y.hat
test.proba <- test.X %*% Y.hat
```

Przedstawmy prognozy klas na wykresach.

```{r train_plot, echo=FALSE, message=FALSE, fig.height=3, fig.cap="Prognozy klas dla zbioru uczacego."}
train.plot <- melt(as.data.frame(train.proba))
train.plot$id <- as.integer(rownames(train.proba))
ggplot(train.plot, aes(x=id, y=value, color=variable)) +
  geom_point()
```

```{r test_plot, echo=FALSE, message=FALSE, fig.height=3, fig.cap="Prognozy klas dla zbioru testowego."}
train.prediction <- colnames(train.proba)[apply(train.proba, 1, which.max)]
test.plot <- melt(as.data.frame(test.proba))
test.plot$id <- as.integer(rownames(test.proba))
ggplot(test.plot, aes(x=id, y=value, color=variable)) +
  geom_point()
```

\newpage

## Ocena jakości klasyfikacji

Wyznaczmy teraz macierz pomyłek dla zbioru uczącego.

```{r training_confusion_matrix, echo=FALSE, eval=TRUE, results='asis'}
train.confusion <- table(train.set$Species, train.prediction)
train.matrix <- as.matrix(train.confusion)
train.matrix %>% kbl(caption="Macierz pomylek dla zbioru uczacego.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))
```

Błąd klasyfikacji to `r 1 - sum(diag(train.confusion)) / length(train.prediction)`.

```{r testing_confusion_matrix, echo=FALSE, eval=TRUE, results='asis'}
test.prediction <- colnames(test.proba)[apply(test.proba, 1, which.max)]
test.confusion <- table(test.set$Species, test.prediction)
test.matrix <- as.matrix(test.confusion)
test.matrix %>% kbl(caption="Macierz pomylek dla zbioru testowego.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))
```

Błąd klasyfikacji wynosi `r  1 - sum(diag(test.confusion)) / length(test.prediction)`.

Wnioski i napomnienie o maskowaniu


## Zastosowanie regresji liniowej do modelu o rozszerzonej ilości cech

Najpierw uzupełnijmy dane o irysach o składniki wielomianowe stopnia $2$.

```{r}
iris.quad <- (iris %>% select(-Species))^2
colnames(iris.quad) <- c("SL^2", "SW^2", "PL^2", "PW^2")
iris <- cbind(iris, combn(iris %>% select(-Species), 2, 
                          FUN = Reduce, f = `*`), 
              iris.quad)
```

Podobnie jak poprzednio podzielimy dane na zbiory: uczący i testowy, a następnie utworzymy macierze: eksperymentu i indykatorów.

```{r}
train.set.index <- sample(1:n, 2/3*n)
train.set <- iris %>% slice(train.set.index) %>% arrange(Species)
test.set <- iris %>% slice(-train.set.index) %>% arrange(Species)

dummies <- dummyVars(" ~ .", data=iris)
train.dummies <- predict(dummies, newdata = train.set)
train.X <- as.matrix(cbind(rep(1, nrow(train.dummies)), train.dummies[, -c(5:7)]))
train.Y <- train.dummies[, 5:7]
test.dummies <- predict(dummies, newdata = test.set) 
test.X <- as.matrix(cbind(rep(1, nrow(test.dummies)), test.dummies[, -c(5:7)]))
test.Y <- test.dummies[, 5:7]
```

Ponownie, wyznaczymy prognozy klas i zwizualizujemy to przypisanie na wykresach.
```{r}
Y.hat <- solve(t(train.X) %*% train.X) %*% t(train.X) %*% train.Y

train.proba <- train.X %*% Y.hat
test.proba <- test.X %*% Y.hat
```

```{r train_plot_2, echo=FALSE, message=FALSE, fig.height=2.8, fig.cap="Prognozy klas dla zbioru uczacego o rozszerzonej liczbie cech."}
train.plot <- melt(as.data.frame(train.proba))
train.plot$id <- as.integer(rownames(train.proba))
ggplot(train.plot, aes(x=id, y=value, color=variable)) +
  geom_point()
```

```{r test_plot_2, echo=FALSE, message=FALSE, fig.height=2.8, fig.cap="Prognozy klas dla zbioru uczacego o rozszerzonej liczbie cech."}
test.plot <- melt(as.data.frame(test.proba))
test.plot$id <- as.integer(rownames(test.proba))
ggplot(test.plot, aes(x=id, y=value, color=variable)) +
  geom_point()
```

Wyznaczymy także macierze pomyłek i błędy klasyfikacji.

```{r training_confusion_matrix_2, echo=FALSE, eval=TRUE, results='asis'}
train.prediction <- colnames(train.proba)[apply(train.proba, 1, which.max)]
train.confusion <- table(train.set$Species, train.prediction)
train.matrix <- as.matrix(train.confusion)
train.matrix %>% kbl(caption="Macierz pomylek dla zbioru uczacego dla przypadku o rozszerzonej liczbie cech.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))
```
Błąd klasyfkacji wynosi `r 1 - sum(diag(train.confusion)) / length(train.prediction)`. 


```{r testing_confusion_matrix_2, echo=FALSE, eval=TRUE, results='asis'}
test.prediction <- colnames(test.proba)[apply(test.proba, 1, which.max)]
test.confusion <- table(test.set$Species, test.prediction)
test.matrix <- as.matrix(test.confusion)
test.matrix %>% kbl(caption="Macierz pomylek dla zbioru testowego dla przypadku o rozszerzonej liczbie cech.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))
```

Błąd klasyfikacji wynosi `r 1 - sum(diag(test.confusion)) / length(test.prediction)`.

Wnioski i napomnienie o maskowaniu

\newpage

# Zadanie 2

## Wczytanie i krótka anliza danych

Wczytajmy i przygotujmy dane do dalszych analizy.

```{r ing and preparing data}
data("BreastCancer")
n <- dim(BreastCancer)[1]

BreastCancer <- BreastCancer %>% select(-Id)
BreastCancer <- drop_na(BreastCancer)
BreastCancer[, 1:9] <- data.frame(sapply(BreastCancer[, 1:9], as.numeric))


for (column in colnames(BreastCancer)) {
  if (is.factor(BreastCancer[, column]) & column != "Class") {
    BreastCancer[, column] <- ordered(BreastCancer[, column])
  }
}
```

Przyjrzyjmy się naszym danym na wykresach pudełkowych.

```{r data boxplot, echo=FALSE, eval=TRUE, fig.cap="Wykresy pudelkowe dla naszch danych."}
plot_boxplot(BreastCancer, by="Class")
```

Możemy zauważyć, że zmiennymi, które dobrze \ldots

Podzielmy nasze dane na zbiór uczący i testowy.

```{r learning and training test}
set.seed(42)
train.index <- sample(n, 2/3 * n)
train.data <- BreastCancer %>% slice(train.index)
test.data <- BreastCancer %>% slice(-train.index)

train.subset <- data.frame(train.data[, c(3, 6, 10)])
test.subset <- data.frame(test.data[, c(3, 6, 10)])
```

```{r}
train.etiquettes <- train.data$Class
test.etiquettes <- test.data$Class
subset.train.etiquettes <- train.subset$Class
subset.test.etiquettes <- test.subset$Class
```

```{r}
cv <- trainControl(method="cv", number=5)
```

## Metoda k-najbliższych sąsiadów 


```{r}
model.knn.basic <- ipredknn(Class ~ ., data = train.data, k=5)

basic.knn.pred <- predict(model.knn.basic, test.data, type="class")

(wynik.tablica <- table(basic.knn.pred, test.etiquettes))

1 - sum(diag(wynik.tablica)) / length(test.etiquettes) 
```


```{r}
knn.model.subset <- ipredknn(Class ~ ., data = train.subset, k=5)

subset.knn.pred <- predict(knn.model.subset, test.subset, type="class")


(wynik.tablica <- table(subset.knn.pred, subset.test.etiquettes))

1 - sum(diag(wynik.tablica)) / length(subset.test.etiquettes) 
```

```{r}
model <- train(Class ~ ., data = train.data, method = "knn", trControl = cv)
confusion <- table(test.data$Class, predict(model, test.data))
confusion
```

```{r}
1 - sum(diag(confusion)) / nrow(test.data)
```


## Drzewa klasyfikacyjne

```{r}
basic.tree.model <- rpart(Class ~ ., data = train.data, control=rpart.control(cp=.03, minsplit=10, maxdepth=10))
fancyRpartPlot(basic.tree.model, sub="")
```

## Naiwny klasyfikator bayesowski


```{r}
bayes.model.basic <- naiveBayes(Class ~ ., data = train.data)

basic.bayes.train.pred <- predict(bayes.model.basic, train.data) 
basic.bayes.test.pred <- predict(bayes.model.basic, test.data)

test.confusion <- table(test.etiquettes, basic.bayes.test.pred)
train.confusion <- table(train.etiquettes, basic.bayes.train.pred)
test.matrix <- as.matrix(test.confusion)
train.matrix <- as.matrix(train.confusion)

test.confusion %>% kbl(caption="Macierz pomylek dla zbioru testowego.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))

test.matrix %>% kbl(caption="Macierz pomylek dla zbioru testowego.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))


print(xtable(train.matrix), file="ta.tex", floating=FALSE)
print(xtable(test.matrix), file="tb.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Table x(a)]{\label{tab:tab1a}\scalebox{.7}{\input{./ta}}}\quad
\subfloat[Table x(b)]{\label{tab:tab1b}\scalebox{.7}{\input{./tb}}}
\caption{Caption about here}
\label{tab:tab1}
\end{table}

Błędy klasyfikacji to kolejno `r 1 - sum(diag(train.matrix)) / length(train.etiquettes)` i `r 1 - sum(diag(test.matrix)) / length(test.etiquettes)`.

Powtórzmy teraz powyższe dla wybranego podzbioru naszych danych.

```{r}
bayes.model.subset <- naiveBayes(Class ~ ., data = train.subset)

basic.bayes.train.pred <- predict(bayes.model.subset, train.subset) 
basic.bayes.test.pred <- predict(bayes.model.subset, test.subset)

test.confusion <- table(subset.test.etiquettes, basic.bayes.test.pred)
train.confusion <- table(subset.train.etiquettes, basic.bayes.train.pred)
test.matrix <- as.matrix(test.confusion)
train.matrix <- as.matrix(train.confusion)

train.matrix %>% kbl(caption="Macierz pomylek dla zbioru testowego.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))

test.matrix %>% kbl(caption="Macierz pomylek dla zbioru testowego.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))


print(xtable(train.matrix), file="tc.tex", floating=FALSE)
print(xtable(test.matrix), file="td.tex", floating=FALSE)
```

Błędy klasyfikacji to kolejno `r 1 - sum(diag(train.matrix)) / length(train.etiquettes)` i `r 1 - sum(diag(test.matrix)) / length(test.etiquettes)`.

Model "stunigowany"

```{r}
model <- train(Class ~ ., data = train.data, method = "naive_bayes", trControl = cv)
test.confusion <- table(test.data$Class, predict(model, test.data))
train.confusion <- table(train.data$Class, predict(model, train.data))

train.confusion %>% as.matrix %>% kbl(caption="Macierz pomylek dla zbioru testowego.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))

test.confusion %>% as.matrix %>% kbl(caption="Macierz pomylek dla zbioru testowego.", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position'))
```

Błędy klasyfikacji w tym przypadku to kolejno `r 1 - sum(diag(train.confusion)) / length(train.etiquettes)` i `r 1 - sum(diag(test.confusion)) / length(test.etiquettes)`.




```{r}
model <- train(Class ~ ., data = train.data, method = "rpart", trControl = cv)
confusion <- table(test.data$Class, predict(model, test.data))
confusion
```

```{r}
sum(diag(confusion)) / nrow(test.data)
```



```{r}
# my.predict  <- function(model, newdata) 
# { predict(model, newdata=newdata) }
# 
# 
# cv <- trainControl(method="cv", number=5)
# 
# 
# my.naiveBayes <- function(formula, data) 
# { train(formula, data = data, method = "naive_bayes", trControl = cv)} 
# 
# 
# my.tree <- function(formula, data)
# { }
# 
# 
# my.knn <- function(formula, data)
# { }
# 
# 
# blad.cv <- errorest(Class~., BreastCancer, model=my.naiveBayes, predict=my.predict, 
#             estimator="cv", est.para=control.errorest(k = 5))
```

