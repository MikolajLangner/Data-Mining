---
title: "Raport 2"
subtitle: "Eksploracja danych"
author:   |
          |    Mikołaj Langner, Marcin Kostrzewa
          |    nr albumów: 255716, 255749
date: "2021-04-19"
output: 
  pdf_document:
    toc: true
    fig_caption: yes
    fig_width: 5 
    fig_height: 4 
    number_sections: true
    includes:
      in_header: "preambula.tex" 
fontsize: 12pt 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=6, fig.height=4)
library(datasets)
library(dplyr)
library(DataExplorer)
library(ggplot2)
library(ggbeeswarm)
library(ggfortify)
library(ggbiplot)
library(ggcorrplot)
library(wesanderson)
library(EnvStats)
library(arules)
library(e1071)
library(kableExtra)
```

# Wstęp
<!--  można napisać trochę więcej -->

Sprawozdanie zawiera rozwiązanie zadań z listy 2. Dotyczą one zagadnień dyskretyzacji i redukcji wymiaru.

# Zadanie 1

W pierwszym zadaniu mamy dokonać dyskretyzacji cech ciągłych ze zbioru `iris` i ocenić jej jakość.

```{r}
data(iris)
```

Wybierzmy zmienne o najlepszej i najgorszej zdolności dyskryminacyjnej. W tym celu &hellip;

```{r include=FALSE}
str(iris)
plot_intro(iris)
plot_boxplot(iris, by="Species")
aggregate(. ~ Species, iris, cv)
```

Porównamy ze sobą cztery metody dyskretyzacji nienadzorowanej:

 - equal width,
 - equal frequency,
 - k-means clustering,
 - dyskretyzację dla przedziałów zadanych przez użytkownika.

```{r message=FALSE}
intervals <- c(min(iris$Petal.Length), 2, 5, max(iris$Petal.Length))
for (method in c("interval", "frequency", "cluster", "fixed")) {
  petal.length.discretized <- if (method != "fixed") 
    discretize(iris$Petal.Length, method=method) else 
    discretize(iris$Petal.Length, method=method, breaks=intervals)
  print(ggplot(iris, aes(Petal.Length)) +
          geom_histogram() +
          geom_vline(xintercept=attributes(petal.length.discretized)$"discretized:breaks") +
          ggtitle(method))
  print(ggplot(iris, aes(Species, Petal.Length)) +
    geom_quasirandom(aes(col=Species)) +
    scale_color_manual(values=wes_palette("GrandBudapest1", 3)) +
    geom_hline(yintercept=attributes(petal.length.discretized)$"discretized:breaks") +
    ggtitle(method))
  discretized.table <- table(petal.length.discretized, iris$Species)
  matchClasses(discretized.table)
}
```

# Zadanie 2

## Wczytanie i przygotowanie danych

Teraz naszym zadaniem jest dokonanie analizy składów głównych (PCA) dla zbioru `state.x77`, który zbiera &hellip;

Wczytajmy dane i uzupełnijmy je o informacje geograficzne o wszytkich stanach.

```{r}
data(state)
state <- as.data.frame(state.x77)
state_ <- state
state_$region <- state.region
state_$division <- state.division
```

By rozstrzygnąć, czy potrzebna jest normalizacja danych, przeanalizujemy wykresy pudełkowe oraz wyznaczymy odchylenia standardowe i współczynniki zmienności.


```{r}
plot_boxplot(data.frame(state, all="all"), by="all")
```

```{r tabela_1, echo=FALSE, eval=TRUE, results='asis'}
var <- sapply(state, function(X) c(sd(X), cv(X)))
summary.matrix <- as.matrix(var)
row.names(summary.matrix) <- c("Odchylenie standardowe", "Wspolczynnik zmiennosci")
summary.matrix %>% kbl(caption="Odchylenie standardowe i wspolczynnik zmiennosci dla zmienych", format="latex", digits=3) %>% kable_styling(latex_options=c('hold_position', 'scale_down'))
```

Widać, że zmienne wymagają standaryzacji.

Wyznaczymy teraz składowe główne i przedstawimy ich rozrzut wykorzystując wykresy budełkowe.

```{r fig.show='hide'}
p1 <- plot_prcomp(state, prcomp_args=list(scale=TRUE, center=TRUE), 
                 variance_cap=1)[1]
```

```{r fig.show='hide'}
p2 <- plot_prcomp(state, prcomp_args=list(scale=TRUE, center=TRUE),
                 variance_cap=0.8)[2]
```

```{r results='hide'}
print(p2)
```



```{r results='hide'}
print(p1)
```

# Zadanie 3