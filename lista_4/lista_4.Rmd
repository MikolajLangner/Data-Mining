---
title: "Raport 4"
subtitle: "Eksploracja danych"
author:   |
          |    Mikołaj Langner, Marcin Kostrzewa
          |    nr albumów: 255716, 255749
date: "2021-05-28"
output: 
  pdf_document:
    toc: true
    fig_caption: yes
    fig_width: 5 
    fig_height: 4 
    number_sections: true
    includes:
      in_header: "preambula.tex" 
fontsize: 12pt 
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=6, fig.height=4, fig.pos='H')
library(ggplot2)
library(caret)
library(kernlab)
library(rattle)
library(ipred)
library(randomForest)
library(dplyr)
library(emdbook)
library(rpart)
library(xtable)
library(tidyr)
library(ggfortify)
library(cluster)
library(cowplot)
library(clValid)
library(e1071)
library(reshape2)
library(DataExplorer)
```


# Wstęp

Niniejszy raport zawiera rozwiązania rozwiązania zadań z listy 4.

W zadaniu pierwszym zastosujemy zaawansowane metody klasyfikacji:
\begin{itemize}
\item bagging,
\item boosting,
\item random forest,
\item metodę wektorów nośnych (SVM),
\end{itemize}

W zadaniu drugim badamy jakość 


\newpage

# Zadanie 1

```{r load.data, echo=FALSE}
data(wine)
n = nrow(wine)

set.seed(42)
train.index <- sample(n, 2/3 * n)
train.data <- wine %>% slice(train.index)
test.data <- wine %>% slice(-train.index)
train.subset <- data.frame(train.data[, c(1, 2, 8)])
test.subset <- data.frame(test.data[, c(1, 2, 8)])
train.etiquettes <- train.data$Type
test.etiquettes <- test.data$Type

cv <- trainControl(method="cv", number=5)
```

## a)

### Pojedyncze drzewo decyzyjne

Przypomnijmy najpierw jak radziła sobie metoda drzewa klasyfikacyjnego.

```{r decision_tree}
tree.model <- rpart(Type ˜ ., data = train.subset, cp=0)
```

Wyglądało ono następująco --- rysunek (\ref{fig::fig1}).

```{r basic_tree_plot, echo=FALSE, eval=TRUE, width=4.5, height=3,fig.cap="\\label{fig:fig1}Pojedyncze drzewo decyzyjne."}
fancyRpartPlot(tree.model, sub="")
```

Przypomnimy także jak wyglądały błędy klasyfikacji dla drzewa.

```{r}
predictor  <- function(model, newdata) 
{ predict(model, newdata=newdata, type = "class") }

decision.tree.predictor <- function(formula, data) 
{ rpart(formula, data = data, cp = 0)}

decision.tree.error.cv <- errorest(Type~., wine[, c(1, 2, 8)], 
                                   model=decision.tree.predictor, 
                                   predict=predictor, estimator="cv", 
                                   est.para=control.errorest(k = 5))
```

Wyniósł on `r decision.tree.error.cv$error`.

### Bagging

Najpierw skorzystamy z algorytmu bagging. Znajdziemy optymalną wartość dla parametru \verb|nbagg|.

```{r nbagg}
B.vector <- c(1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)
bagging.error.rates <- sapply(B.vector, function(b)  
  {errorest(Type~., data=train.data, model=bagging, 
            nbagg=b, estimator="632plus",
            est.para=control.errorest(nboot = 20))$error})
choice <- B.vector[which.min(bagging.error.rates)]
```

```{r nbagg_plot, eval=TRUE, echo=FALSE, fig.cap="\\label{fig::2} Wplyw ilosci replikacji na blad klasyfikacji."}
ggplot(data = data.frame(B=B.vector, x=bagging.error.rates), aes(B, x)) + 
  geom_line(color="red") + geom_point() + xlab('Ilosc replikacji') + ylab('Wartosc bledu')
```

Jak widać, najlepiej zbudować model dla nbagg równego `r choice`.

```{r bagging_pred}
bagging.model <- bagging(Type~., data=train.data, nbagg=choice,
                         minsplit=1, cp=0)
bagging.train.pred <- predict(bagging.model, train.data)
bagging.test.pred <- predict(bagging.model, test.data)
```

Wyznaczymy dla tego modelu macierze pomyłek i wartości błędów klasyfkacji.

```{r bagging_confusion, echo=FALSE, eval=TRUE}
test.confusion <- table(bagging.test.pred, test.etiquettes)
train.confusion <- table(bagging.train.pred, train.etiquettes)

print(xtable(train.confusion), file="bag1.tex", floating=FALSE)
print(xtable(test.confusion), file="bag2.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:bag1}{\input{./bag1}}}\quad
\subfloat[Zbior testowy]{\label{tab:bag2}{\input{./bag2}}}
\caption{Macierze pomylek dla algorytmu bagging.}
\label{tab:tab_bag1}
\end{table}

Błędy klasyfikacji to kolejno `r 1 - sum(diag(train.confusion)) / length(train.etiquettes) ` i `r 1 - sum(diag(test.confusion)) / length(test.etiquettes)`.

Wyznaczymy teraz dla tego modelu klasyfikacyjnego błąd predykcji --- skorzystamy z $5$-krotnej walidacji krzyżowej, metody bootstrap oraz \verb|.632+|.

```{r bagging_errors}
predictor  <- function(model, newdata) 
{predict(model, newdata=newdata, type = "class")}

bagging.predictor <- function(formula, data) 
{bagging(formula, data = data, nbagg = choice, cp = 0)}

bagging.error.cv <- errorest(Type~., wine, 
                                   model=bagging.predictor, 
                                   predict=predictor, estimator="cv", 
                                   est.para=control.errorest(k = 5))
bagging.error.boot <- errorest(Type~., wine, 
                                     model=bagging.predictor, 
                                     predict=predictor, estimator="boot", 
                                     est.para=control.errorest(nboot = 25))
bagging.error.632 <- errorest(Type~., wine, 
                                     model=bagging.predictor, 
                                     predict=predictor, estimator="632plus", 
                                     est.para=control.errorest(nboot = 25))
```

Błędy wyniosły kolejno `r bagging.error.cv$error`, `r bagging.error.boot$error` oraz `r bagging.error.632$error`.


### Boosting


### Random Forest

Teraz wykorzystamy algorytm random forrest.

Postaramy się odpowiednio dobrać parametry \verb|ntree| (ilość drzew) i \verb|mtry| (ilość losowo wybieranych cech).


```{r}
ntree.vector <- seq(10, 500, by=20)
ntree.error.rates <- sapply(ntree.vector, function(b)  
  {errorest(Type~., data=train.data, model=randomForest, 
            ntree=b, estimator="632plus",
            est.para=control.errorest(nboot = 20))$error})
ntree.choice <- ntree.vector[which.min(ntree.error.rates)]

mtry.vector <- seq(1, sqrt(ncol(wine))+1, by=1)
mtry.error.rates <- sapply(mtry.vector, function(m) 
  {errorest(Type~., data=train.data, model=randomForest, ntree = ntree.choice, 
            mtry=m, estimator="632plus",
            est.para=control.errorest(nboot = 20))$error})
mtry.choice <- mtry.vector[which.min(mtry.error.rates)]
```

```{r mtry_ntree_plots, echo=FALSE, eval=TRUE, fig.cap="\\label{fig:3} Wykresy zaleznosci bledu klasyfikacji od parametrow mtry i ntree."}
p1 <- ggplot(data = data.frame(ntree=ntree.vector, error=ntree.error.rates), aes(ntree, error)) + 
  geom_line() + geom_point() + theme_dark()

p2 <- ggplot(data = data.frame(mtry=mtry.vector, error=mtry.error.rates), aes(mtry, error)) + 
  geom_line() + geom_point() + theme_dark()

plot_grid(p1, p2)
```

Podobnie jak wcześniej wyznaczamy za pomocą modelu etykietki klas i wyznaczamy macierze pomyłek i błędy klasyfikacji.

```{r randomforrest_model}
rf.model <- randomForest(Type ~., data = train.data, ntree=ntree.choice,
                         mtry=mtry.choice, importance=TRUE)
rf.test.pred <- predict(rf.model, test.data)
rf.train.pred <- predict(rf.model, train.data)
```

```{r confusion_tables_rf, echo=FALSE, eval=TRUE}
test.confusion <- table(rf.test.pred, test.etiquettes)
train.confusion <- table(rf.train.pred, train.etiquettes)

print(xtable(train.confusion), file="rf1.tex", floating=FALSE)
print(xtable(test.confusion), file="rf2.tex", floating=FALSE)
```

\begin{table}[ht]
\centering
\subfloat[Zbior uczacy]{\label{tab:rf1}{\input{./rf1}}}\quad
\subfloat[Zbior testowy]{\label{tab:rf2}{\input{./rf2}}}
\caption{Macierze pomylek dla algorytmu randomForest.}
\label{tab:tab_rf}
\end{table}

Błędy klasyfikacji to kolejno `r 1 - sum(diag(train.confusion)) / length(train.etiquettes) ` i `r 1 - sum(diag(test.confusion)) / length(test.etiquettes)`.

Tak jak wcześniej wyznaczymy dla tego modelu błędy predykcji.

```{r rf_errors}
predictor  <- function(model, newdata) 
{ predict(model, newdata=newdata, type = "class") }

rf.predictor <- function(formula, data) 
{ randomForest(formula, data = data, ntree = ntree.choice, mtry = mtry.choice)}

rf.error.cv <- errorest(Type~., wine, model=rf.predictor, 
                                   predict=predictor, estimator="cv", 
                                   est.para=control.errorest(k = 5))
rf.error.boot <- errorest(Type~., wine, model=rf.predictor, 
                                     predict=predictor, estimator="boot", 
                                     est.para=control.errorest(nboot = 25))
rf.error.632 <- errorest(Type~., wine, model=rf.predictor, 
                                     predict=predictor, estimator="632plus", 
                                     est.para=control.errorest(nboot = 25))
```

Błędy wyniosły kolejno `r rf.error.cv$error`, `r rf.error.boot$error` oraz `r rf.error.632$error`.


Wykorzystamy teraz algorytm random forest do wyznaczenia rankingu cech (\textit{variable importance}). 

```{r importance_plot, echo=FALSE, eval=TRUE, fig.cap="\\label{fig::4} Wykres waznosci zmiennych."}
acc = data.frame(variable=as.vector(colnames(wine))[-1], val=importance(rf.model)[, 4]) %>%
  arrange(desc(val))
gini = data.frame(variable=as.vector(colnames(wine))[-1], val=importance(rf.model)[, 5]) %>%
  arrange(desc(val))

p1 <- ggplot(data = acc, aes(x=reorder(variable, val), y=val, fill=variable)) + geom_bar(stat="identity") + coord_flip() + theme(legend.position="none") + xlab("Zmienne") + ylab("MeanAccuracyDecrease")
p2 <- ggplot(data = gini, aes(x=reorder(variable, val), y=val, fill=variable)) + geom_bar(stat="identity") + coord_flip() + theme(legend.position="none") + xlab("") + ylab("MeanGiniDecrease")

plot_grid(p1, p2)
```

Widzimy, że \ldots


### Wnioski

## b)

```{r}
wine <- wine %>% select(c(Type, Alcohol, Flavanoids))
```

```{r SVM.class.err, echo=FALSE, fig.cap="Dokładność klasyfikatora od parametru kosztu"}
models <- train(Type ~.,
               data = wine,
               method = "svmLinear",
               trControl = trainControl(method = "cv"),
               tuneGrid = expand.grid(C = lseq(1e-1, 1e3, 5)))
ggplot(models$results, aes(C, Accuracy)) + geom_line() + scale_y_log10() + scale_x_log10()
```

```{r SVM.decision.bound.01, echo=FALSE, message=FALSE, fig.cap="Obszary decyzyjne dla $C=0.1$"}
model <- ksvm(Type ~., data = wine, kernel = "vanilladot", C = 1e-1)

var1 <- wine$Alcohol
var2 <- wine$Flavanoids
x.test <- expand.grid(Alcohol = seq(min(var1), max(var1), by = 0.05), 
                      Flavanoids = seq(min(var2), max(var2), by = 0.05))

df1 <- data.frame(x.test, class = predict(model, x.test))
df2 <- data.frame(x = wine$Alcohol, y = wine$Flavanoids,
                  class = wine$Type)

ggplot() +
  geom_point(aes(x=Alcohol, y=Flavanoids, col = class), data = df1, size = .5) + 
  geom_point(aes(x=x, y=y, col=class), data = df2, size = 4.5, shape = 1) + 
  theme_bw() 
```

```{r SVM.decision.bound.1, echo=FALSE, message=FALSE, fig.cap="Obszary decyzyjne dla $C=1$"}
model <- ksvm(Type ~., data = wine, kernel = "vanilladot", C = 1e0)

var1 <- wine$Alcohol
var2 <- wine$Flavanoids
x.test <- expand.grid(Alcohol = seq(min(var1), max(var1), by = 0.05), 
                      Flavanoids = seq(min(var2), max(var2), by = 0.05))

df1 <- data.frame(x.test, class = predict(model, x.test))
df2 <- data.frame(x = wine$Alcohol, y = wine$Flavanoids,
                  class = wine$Type)

ggplot() +
  geom_point(aes(x=Alcohol, y=Flavanoids, col = class), data = df1, size = .5) + 
  geom_point(aes(x=x, y=y, col=class), data = df2, size = 4.5, shape = 1) + 
  theme_bw() 
```

```{r SVM.decision.bound.10, echo=FALSE, message=FALSE, fig.cap="Obszary decyzyjne dla $C=10$"}
model <- ksvm(Type ~., data = wine, kernel = "vanilladot", C = 1e1)

var1 <- wine$Alcohol
var2 <- wine$Flavanoids
x.test <- expand.grid(Alcohol = seq(min(var1), max(var1), by = 0.05), 
                      Flavanoids = seq(min(var2), max(var2), by = 0.05))

df1 <- data.frame(x.test, class = predict(model, x.test))
df2 <- data.frame(x = wine$Alcohol, y = wine$Flavanoids,
                  class = wine$Type)

ggplot() +
  geom_point(aes(x=Alcohol, y=Flavanoids, col = class), data = df1, size = .5) + 
  geom_point(aes(x=x, y=y, col=class), data = df2, size = 4.5, shape = 1) + 
  theme_bw() 
```

```{r SVM.decision.bound.100, echo=FALSE, message=FALSE, fig.cap="Obszary decyzyjne dla $C=100$"}
model <- ksvm(Type ~., data = wine, kernel = "vanilladot", C = 1e2)

var1 <- wine$Alcohol
var2 <- wine$Flavanoids
x.test <- expand.grid(Alcohol = seq(min(var1), max(var1), by = 0.05), 
                      Flavanoids = seq(min(var2), max(var2), by = 0.05))

df1 <- data.frame(x.test, class = predict(model, x.test))
df2 <- data.frame(x = wine$Alcohol, y = wine$Flavanoids,
                  class = wine$Type)

ggplot() +
  geom_point(aes(x=Alcohol, y=Flavanoids, col = class), data = df1, size = .5) + 
  geom_point(aes(x=x, y=y, col=class), data = df2, size = 4.5, shape = 1) + 
  theme_bw() 
```

```{r SVM.decision.bound.1000, echo=FALSE, message=FALSE, fig.cap="Obszary decyzyjne dla $C=1000$"}
model <- ksvm(Type ~., data = wine, kernel = "vanilladot", C = 1e3)

var1 <- wine$Alcohol
var2 <- wine$Flavanoids
x.test <- expand.grid(Alcohol = seq(min(var1), max(var1), by = 0.05), 
                      Flavanoids = seq(min(var2), max(var2), by = 0.05))

df1 <- data.frame(x.test, class = predict(model, x.test))
df2 <- data.frame(x = wine$Alcohol, y = wine$Flavanoids,
                  class = wine$Type)

ggplot() +
  geom_point(aes(x=Alcohol, y=Flavanoids, col = class), data = df1, size = .5) + 
  geom_point(aes(x=x, y=y, col=class), data = df2, size = 4.5, shape = 1) + 
  theme_bw() 
```


```{r SVM.kernels, results='asis', echo=FALSE, message=FALSE, warning=FALSE}
models.linear <- train(Type ~.,
               data = wine,
               method = "svmLinear",
               trControl = trainControl(method = "cv"),
               tuneGrid = expand.grid(C = lseq(1e-1, 1e3, 5)))
models.poly <- train(Type ~.,
               data = wine,
               method = "svmPoly",
               trControl = trainControl(method = "cv"),
               tuneGrid = expand.grid(C = lseq(1e-1, 1e3, 5), degree = seq(1, 5, 1), scale = seq(.2, 1, .2)))
models.radial <- train(Type ~.,
               data = wine,
               method = "svmRadial",
               trControl = trainControl(method = "cv"),
               tuneGrid = expand.grid(C = lseq(1e-1, 1e3, 5), sigma = lseq(1e-4, 1e0, 5)))

result.linear <- models.linear$results[which.max(models.linear$results$Accuracy), "Accuracy"]
result.poly <- models.poly$results[which.max(models.poly$results$Accuracy), "Accuracy"]
result.radial <- models.radial$results[which.max(models.radial$results$Accuracy), "Accuracy"]
print(xtable(as.tibble(list(linear=result.linear, polynomial=result.poly, radial=result.radial)), digits=3, caption="Porównanie klasyfikatorów dla różnych jąder"), include.rownames=FALSE)
```

```{r tune.radial, echo=FALSE, message=FALSE, fig.cap="Mapa ciepła dokładności klasyfikatora"}
models.radial <- train(Type ~.,
               data = wine,
               method = "svmRadial",
               trControl = trainControl(method = "cv"),
               tuneGrid = expand.grid(C = lseq(1e-1, 1e3, 5), sigma = lseq(1e-4, 1e0, 5)))
ggplot(models.radial$results, aes(C, sigma, fill=Accuracy)) + geom_tile() + scale_y_log10() + scale_x_log10()
```

```{r tune.radial.table, results='asis', echo=FALSE, message=FALSE}
print(xtable(models.radial$bestTune, caption = "Parametry dla najlepszego klasyfikatora"), include.rownames=FALSE)
```

# Zadanie 2

```{r clusters, echo=FALSE, message=FALSE, warning=FALSE, fig.height=8}
data(wine)
clusters <- pam(scale(wine %>% select(-Type)), 3)
wine$Predicted <- as.factor(clusters$clustering)
p1 <- autoplot(prcomp(wine %>% select(-c(Type, Predicted)), scale = TRUE),
         data = wine, colour = 'Predicted', shape='Type', frame=TRUE, frame.type='norm')
p2 <- autoplot(prcomp(wine %>% select(-c(Type, Predicted)), scale = TRUE),
         data = wine, colour = 'Type', shape='Predicted', frame=TRUE, frame.type='norm')
plot_grid(p1, p2, ncol=1)
```

```{r internal, echo=FALSE}
data(wine)
cl.methods <- c("agnes", "pam")
cl.range <- 2:10
internal <- clValid(wine %>% select(-Type),
                    nClust=cl.range, clMethods=cl.methods, validation="internal")
summary(internal)
optimalScores(internal)

par(mfrow = c(2, 2))
plot(internal, legend = FALSE, lwd=2)
plot.new()
legend("center", clusterMethods(internal), col=1:9, lty=1:9, pch=paste(1:9))
```

```{r external, echo=FALSE}
pam.match <- Vectorize(function(k) {
  pam.table <-  table(pam(scale(wine %>% select(-Type)), k)$clustering, wine$Type)
  sum(diag(pam.table)) / sum(pam.table)
}
)

agnes.single.match <- Vectorize(function(k) {
  agnes.single.table <-  table(cutree(agnes(scale(wine %>% select(-Type)), method='single'), k), wine$Type)
  sum(diag(agnes.single.table)) / sum(agnes.single.table)
}
)

agnes.complete.match <- Vectorize(function(k) {
  agnes.complete.table <-  table(cutree(agnes(scale(wine %>% select(-Type)), method='complete'), k), wine$Type)
  sum(diag(agnes.complete.table)) / sum(agnes.complete.table)
}
)

df <- data.frame(k = seq(2, 10))
df$pam <- pam.match(df$k)
df$agnes.single <- agnes.single.match(df$k)
df$agnes.complete <- agnes.complete.match(df$k)

ggplot(melt(df, id.vars = 'k', variable.name = 'method', value.name = 'agreement')) +
  geom_line(aes(x=k, y=agreement, color=method))

```


```{r cluster boxplots}
wine.pam <- pam(scale(wine %>% select(-Type)), 3)
wine.agnes <- cutree(agnes(scale(wine %>% select(-Type)), method='complete'), 3)

wine$pam <- as.factor(wine.pam$clustering)
wine$agnes <- as.factor(wine.agnes)

plot_boxplot(wine, by='pam')
plot_boxplot(wine, by='agnes')
```

```{r medoids}
wine.pam$medoids
```

